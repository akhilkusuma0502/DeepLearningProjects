{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST_Image_Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdosS3kdyBPyU63lfrAqKo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilkusuma0502/DeepLearningProjects/blob/master/Fashion_MNIST_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwhrNq5jk65b",
        "colab_type": "text"
      },
      "source": [
        "**Computer Vision using Tensorflow demo**: Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zkpw__jhIgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwjIWXlVNoac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs={}):\n",
        "    if(logs.get('accuracy')>0.99):\n",
        "      print(\"\\nReached 99% Accuracy, Thus Cancelling Training!!!\")\n",
        "      self.model.stop_training=True"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRkHg30JlKXu",
        "colab_type": "text"
      },
      "source": [
        "import necessary libraries required.\n",
        "We need **tensorflow** library and **Keras** API in order to perform any deep learning neural nets.\n",
        "we also array since we are dealing with matrices, we need **numpy** array . so import **numpy** as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxSBKCQohcKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MNISt=keras.datasets.fashion_mnist"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjDw4xGzliPu",
        "colab_type": "text"
      },
      "source": [
        "MNIST is the dataset offered by Keras to perform basic image classification. It involves fashion clothing items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF2fJtpNlyBP",
        "colab_type": "text"
      },
      "source": [
        "**The next we need to do is Features Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p727K5U1hjDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(training_images , training_labels),(test_images,test_labels)=MNISt.load_data()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOczV3QCl5ju",
        "colab_type": "text"
      },
      "source": [
        "In the above code, i have used to sets where one set will capture training features and training labels and another set will capture test features and test labels.\n",
        "load_Data() returns multiple parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR-o4qc8mQuf",
        "colab_type": "text"
      },
      "source": [
        "# **Lets Visualize one of the item from Training Images and see how it looks like**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaeUb1RahpLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7f226cc2-d6c0-4f93-9709-79ea341baec5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luuXPyItm21G",
        "colab_type": "text"
      },
      "source": [
        "The above image is 25*25 pixel image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoWxbw4-nXSH",
        "colab_type": "text"
      },
      "source": [
        "**It is better to Normalize the data. Neural Networks best if the values are between 0 and 1**\n",
        "\n",
        "Since we are dealing with images , we need to understand that its pixel values ranges from 0 to 255 and hence divide the matrix/array by 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkRyOHseiBP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or6jpBw4nsCo",
        "colab_type": "text"
      },
      "source": [
        "**Add layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmqVrsxviXo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                  tf.keras.layers.Dense(10,activation=tf.nn.softmax)])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP1uo-OiHtEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks=myCallback()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCDZguDXo4ZP",
        "colab_type": "text"
      },
      "source": [
        "**Flatten**: The input shape is 28*28 , so flatten job is to take the rectangular input and flatten it to one-dimensional array and pass it to other layers.\n",
        "\n",
        "**Dense**: Since input is Densely connected to 128 neurons. 128 is arbitary. You can try different numbers as well. Use Relu Activation since it outputs 0 or 1.\n",
        "\n",
        "**Dense**: Output layer. Since we have 10 different categories in the training data. If so check the unique values of taining_labels.\n",
        "\n",
        "**Softmax**: Commonly seen on final layers if there are multiple categories to output. The idea is simple , the output of the neuron is a probability value ans softmax helps us to set highest value to 1 and other to 0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1IVP5LUi3l6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "0778c6c1-36bf-4f05-db3d-281cf85d6c21"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images,training_labels,epochs=5,callbacks=[callbacks])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2806 - accuracy: 0.8975\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2666 - accuracy: 0.9014\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2567 - accuracy: 0.9044\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2477 - accuracy: 0.9073\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2376 - accuracy: 0.9112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2f6ed790b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUxtR66wqnlh",
        "colab_type": "text"
      },
      "source": [
        "**Compile the model**\n",
        "\n",
        "While compiling the model , Three things to keep in mind.\n",
        "**Optimizer**: There are different optimizers but the idea is to reduce the loss which is called Gradient Descent. The Goal of Gradient Descent is to find weights and bias that minimizes the J(w,b) i,e.., Cost Function.\n",
        "\n",
        "**loss**: Choose sparse_categorical_crossentropy since we have categorical outputs.\n",
        "\n",
        "**metrics**: What metrics do you want to cover. In here, we are covering accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdqnV4OKsSpQ",
        "colab_type": "text"
      },
      "source": [
        "# Fit the model after that using training images, training labels and number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58PmPVPUjQIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1cf1c3aa-fa2f-4db4-8161-f7459e19aa37"
      },
      "source": [
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3474550247192383, 0.8756999969482422]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SirEVkRpsHQK",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model using test images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4AsLoMLskWQ",
        "colab_type": "text"
      },
      "source": [
        "Close to 98% Which is Great and our model with Traing also got 98% . Our neural network is working fine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5Paq7qZszEf",
        "colab_type": "text"
      },
      "source": [
        "Lets see single picture from test data and see what it predicts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC3gqwHwsyiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "dcd076bf-ec14-4f61-e90d-5de515e9c619"
      },
      "source": [
        "plt.imshow(test_images[9])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2f70896e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egSsrZn9ulXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=model.predict(test_images)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwI5u1x2wfN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9705ece0-4d85-45ad-b81b-80d1a8642f26"
      },
      "source": [
        "np.argmax(predictions[9])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NRG9l5iwxsV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "0\tT-shirt/top\n",
        "\n",
        "1\tTrouser\n",
        "\n",
        "2\tPullover\n",
        "\n",
        "3\tDress\n",
        "\n",
        "4\tCoat\n",
        "\n",
        "5\tSandal\n",
        "\n",
        "6\tShirt\n",
        "\n",
        "7\tSneaker\n",
        "\n",
        "8\tBag\n",
        "\n",
        "9\tAnkle boot"
      ]
    }
  ]
}